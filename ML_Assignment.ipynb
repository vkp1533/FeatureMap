{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtL4dsSIUIA5Rf26BmWEoJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vkp1533/FeatureMap/blob/main/ML_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARJEfDiibeYt"
      },
      "outputs": [],
      "source": [
        "# Implementing Single Perceptron over wine dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# Load wine dataset\n",
        "train = pd.read_csv('/content/drive/MyDrive/ML_Datasets/wine_train.csv')\n",
        "test  = pd.read_csv('/content/drive/MyDrive/ML_Datasets/wine_test.csv')\n",
        "# X = features, y = target\n",
        "X_tr = train.drop('target', axis=1).values  # (5000, 13)\n",
        "X_te = test.drop('target', axis=1).values   # (1500, 13)\n",
        "y_tr = train['target'].values.reshape(-1, 1)  # (5000, 1)\n",
        "y_te = test['target'].values.reshape(-1, 1)    # (1500, 1)\n",
        "# Z-score scaling\n",
        "mean = X_tr.mean(axis=0)\n",
        "std  = X_tr.std(axis=0)\n",
        "std[std == 0] = 1\n",
        "X_tr = (X_tr - mean) / std\n",
        "X_te = (X_te - mean) / std\n",
        "\n",
        "# Perceptron weights (1 neuron)\n",
        "np.random.seed(42)\n",
        "n_feat = X_tr.shape[1]\n",
        "# Input -> Output weights\n",
        "w = np.random.randn(n_feat, 1) * 0.1\n",
        "b = 0.0\n",
        "\n",
        "for epoch in range(300):\n",
        "    for i in range(len(X_tr)):\n",
        "        # Forward: z = x·w + b\n",
        "        z = X_tr[i] @ w + b\n",
        "        pred = 1 if z >= 0 else 0           # Step function (0 or 1)\n",
        "\n",
        "        # Error\n",
        "        err = y_tr[i] - pred\n",
        "\n",
        "        # Update: w = w + lr * err * x\n",
        "        w += 0.1 * err * X_tr[i].reshape(-1, 1)\n",
        "        b += 0.1 * err\n",
        "# Test prediction\n",
        "z_te = X_te @ w + b\n",
        "pred = (z_te >= 0).astype(int)          # 1 if z >= 0 else 0\n",
        "\n",
        "accuracy = np.mean(pred == y_te) * 100\n",
        "print(f\"\\nPERCEPTRON ACCURACY (Wine): {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#implementing multilayer perceptron\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Loading wine training and testing datasets\n",
        "train = pd.read_csv('/content/drive/MyDrive/ML_Datasets/wine_train.csv')\n",
        "test  = pd.read_csv('/content/drive/MyDrive/ML_Datasets/wine_test.csv')\n",
        "\n",
        "# X for features, y for target (0/1)\n",
        "# Data preprocessing\n",
        "X_tr = train.drop('target', axis=1).values\n",
        "X_te = test.drop('target', axis=1).values\n",
        "y_tr = train['target'].values.reshape(-1, 1)\n",
        "y_te = test['target'].values.reshape(-1, 1)\n",
        "\n",
        "# Z-score scaling (mean=0, std=1)\n",
        "mean = X_tr.mean(axis=0)  # Mean of features\n",
        "# Standard deviation of each feature\n",
        "std  = X_tr.std(axis=0)\n",
        "# Prevent divide by zero\n",
        "std[std == 0] = 1\n",
        "\n",
        "\n",
        "X_tr = (X_tr - mean) / std\n",
        "# Scaled test features (same mean/std)\n",
        "X_te = (X_te - mean) / std\n",
        "\n",
        "# MLP weights\n",
        "np.random.seed(42)\n",
        " # total no. of features\n",
        "n_feat = X_tr.shape[1]\n",
        "\n",
        "W1 = np.random.randn(n_feat, 16) * 0.5   # Input -> Hidden (13 x 16)\n",
        "b1 = np.zeros((1, 16))                   # Hidden bias\n",
        "W2 = np.random.randn(16, 1) * 0.5        # Hidden -> Output (16 x 1)\n",
        "b2 = np.zeros((1, 1))                    # Output bias\n",
        "for epoch in range(150):\n",
        "    # Forward pass\n",
        "    Z1 = X_tr @ W1 + b1\n",
        "    # Linear (13 -> 16)\n",
        "    A1 = np.maximum(0, Z1)\n",
        "    # ReLU activation\n",
        "    Z2 = A1 @ W2 + b2\n",
        "    # Linear (16 -> 1)\n",
        "    A2 = 1 / (1 + np.exp(-Z2))             # Sigmoid output (0 to 1)\n",
        "\n",
        "    # Gradients calc\n",
        "    # Output error\n",
        "    err = A2 - y_tr\n",
        "    # Gradient for W2\n",
        "    dW2 = A1.T @ err / len(X_tr)\n",
        "    # Gradient for W1 (ReLU deriv = Z1>0)\n",
        "    dW1 = X_tr.T @ (err @ W2.T * (Z1 > 0)) / len(X_tr)\n",
        "    # Update weights (learning rate = 0.1)\n",
        "    W1 -= 0.1 * dW1\n",
        "    W2 -= 0.1 * dW2\n",
        "\n",
        "# Testing\n",
        "Z1_te = X_te @ W1 + b1\n",
        "A1_te = np.maximum(0, Z1_te)\n",
        "A2_te = 1 / (1 + np.exp(-(A1_te @ W2 + b2)))\n",
        "# keeping threshold 0.5\n",
        "pred = (A2_te > 0.5).astype(int)\n",
        "\n",
        "accuracy = np.mean(pred == y_te) * 100\n",
        "print(f\"\\nMLP ACCURACY (Wine): {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "q9Q884owT816",
        "outputId": "260d5f29-95c7-4c22-910f-8b6ba39d0d70"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MLP ACCURACY (Wine): 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. DATA LOAD\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/ML_Datasets/wine_train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/ML_Datasets/wine_test.csv')\n",
        "\n",
        "X_train = train_df.iloc[:, 1:].values\n",
        "y_train = np.where(train_df['target'].values == 0, -1, 1)\n",
        "X_test = test_df.iloc[:, 1:].values\n",
        "y_test = np.where(test_df['target'].values == 0, -1, 1)\n",
        "\n",
        "# 2. NORMALIZE (important for soft margin)\n",
        "X_train = (X_train - X_train.mean(axis=0)) / X_train.std(axis=0)\n",
        "X_test = (X_test - X_test.mean(axis=0)) / X_test.std(axis=0)\n",
        "\n",
        "# 3. SOFT MARGIN SVM – SIRF 10 LINES!\n",
        "def soft_margin_svm(X, y, C=1.0, learning_rate=0.001, epochs=1000):\n",
        "    n_samples, n_features = X.shape\n",
        "    w = np.zeros(n_features)   # w shuru mein 0\n",
        "    b = 0                      # b = 0\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        for i in range(n_samples):\n",
        "            # Condition: y_i * (w·x_i + b) >= 1\n",
        "            condition = y[i] * (np.dot(X[i], w) + b) >= 1\n",
        "\n",
        "            if condition:\n",
        "                # Sirf w ko update karo (galti nahi)\n",
        "                w -= learning_rate * (2 * 0.01 * w)  # L2 regularization\n",
        "            else:\n",
        "                # Galti hai → w aur b dono update\n",
        "                w -= learning_rate * (2 * 0.01 * w - y[i] * X[i])\n",
        "                b -= learning_rate * (-y[i])\n",
        "\n",
        "    return w, b\n",
        "\n",
        "# 4. TRAIN KARO (C = 1.0 → thoda soft)\n",
        "w, b = soft_margin_svm(X_train, y_train, C=1.0, epochs=500)\n",
        "\n",
        "# 5. PREDICT\n",
        "def predict(X, w, b):\n",
        "    return np.sign(X @ w + b)\n",
        "\n",
        "y_pred = predict(X_test, w, b)\n",
        "accuracy = np.mean(y_pred == y_test)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4ra5wUD-A_qc",
        "outputId": "92c0d6e3-8789-419d-fc7c-ab04f54f309f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/ML_Datasets/wine_train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/ML_Datasets/wine_test.csv')\n",
        "# 2. X aur y\n",
        "X_train = train.iloc[:, 1:].values\n",
        "y_train = train['target'].values\n",
        "X_test = test.iloc[:, 1:].values\n",
        "y_test = test['target'].values\n",
        "\n",
        "# 3. Normalize\n",
        "X_train_mean = X_train.mean(axis=0)\n",
        "X_train_std = X_train.std(axis=0)\n",
        "X_train = (X_train - X_train_mean) / X_train_std\n",
        "X_test = (X_test - X_train_mean) / X_train_std\n",
        "\n",
        "# 4. K select (odd)\n",
        "n_test = len(X_test)\n",
        "k = int(np.sqrt(n_test))\n",
        "if k % 2 == 0:\n",
        "    k += 1\n",
        "print(f\"K = {k}\")\n",
        "\n",
        "# 5. Distance function\n",
        "def euclidean_distance(p1, p2):\n",
        "    return np.sqrt(np.sum((p1 - p2) ** 2))\n",
        "\n",
        "# 6. KNN predict\n",
        "def knn_predict(test_point, X_train, y_train, k):\n",
        "    distances = []\n",
        "    for i in range(len(X_train)):\n",
        "        dist = euclidean_distance(test_point, X_train[i])\n",
        "        distances.append((dist, y_train[i]))\n",
        "    distances.sort(key=lambda x: x[0])\n",
        "    neighbors = distances[:k]\n",
        "    count_0 = sum(1 for _, label in neighbors if label == 0)\n",
        "    count_1 = k - count_0\n",
        "    return 0 if count_0 > count_1 else 1\n",
        "\n",
        "# 7. Predict all\n",
        "y_pred = [knn_predict(X_test[i], X_train, y_train, k) for i in range(len(X_test))]\n",
        "y_pred = np.array(y_pred)\n",
        "\n",
        "# 8. Accuracy\n",
        "accuracy = np.mean(y_pred == y_test)\n",
        "print(f\"Accuracy: {accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3E_BHSxlDceG",
        "outputId": "e41ed365-5d85-4e18-ac80-35553bb8e069"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K = 7\n",
            "Accuracy: 97.22%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA\n",
        "#Implementing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. Load data\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/ML_Datasets/adult_train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/ML_Datasets/adult_test.csv')\n",
        "\n",
        "# 2. Features only\n",
        "X_train = train.iloc[:, 1:].values\n",
        "X_test = test.iloc[:, 1:].values\n",
        "\n",
        "# 3. Mean centering\n",
        "mean_vector = X_train.mean(axis=0)\n",
        "X_centered = X_train - mean_vector\n",
        "\n",
        "# 4. Covariance matrix\n",
        "cov_matrix = np.cov(X_centered, rowvar=False)\n",
        "\n",
        "# 5. Eigen decomposition\n",
        "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
        "\n",
        "# 6. Sort by importance\n",
        "idx = eigenvalues.argsort()[::-1]\n",
        "eigenvalues = eigenvalues[idx]\n",
        "eigenvectors = eigenvectors[:, idx]\n",
        "\n",
        "# 7. Explained variance\n",
        "total = eigenvalues.sum()\n",
        "exp_var = eigenvalues / total\n",
        "cum_var = np.cumsum(exp_var)\n",
        "\n",
        "print(\"Explained Variance:\")\n",
        "for i in range(5):\n",
        "    print(f\"PC{i+1}: {exp_var[i]*100:.2f}%\")\n",
        "print(f\"First 2 PCs: {cum_var[1]*100:.2f}%\")\n",
        "\n",
        "# 8. Choose top 2\n",
        "n_components = 2\n",
        "W = eigenvectors[:, :n_components]\n",
        "\n",
        "# 9. Project data\n",
        "X_pca_train = X_centered @ W\n",
        "X_pca_test = (X_test - mean_vector) @ W\n",
        "\n",
        "print(f\"\\nOriginal: {X_train.shape} → PCA: {X_pca_train.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ftscXzNwEniG",
        "outputId": "9c379491-8229-4d78-a532-dc5b54500a54"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explained Variance:\n",
            "PC1: 99.76%\n",
            "PC2: 0.22%\n",
            "PC3: 0.01%\n",
            "PC4: 0.01%\n",
            "PC5: 0.00%\n",
            "First 2 PCs: 99.98%\n",
            "\n",
            "Original: (36, 13) → PCA: (36, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SVD\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. Load data\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/ML_Datasets/adult_train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/ML_Datasets/adult_test.csv')\n",
        "\n",
        "# 2. Numeric columns only\n",
        "cols = [1, 2, 4, 10, 11, 12]  # age, fnlwgt, edu-num, cap-gain, cap-loss, hours\n",
        "X_train = train.iloc[:, cols].values\n",
        "\n",
        "# 3. Mean centering\n",
        "mean_vec = X_train.mean(axis=0)\n",
        "X_centered = X_train - mean_vec\n",
        "\n",
        "# 4. SVD from scratch\n",
        "def svd_scratch(X):\n",
        "    A = X @ X.T\n",
        "    eig_U, U = np.linalg.eig(A)\n",
        "    B = X.T @ X\n",
        "    eig_V, V = np.linalg.eig(B)\n",
        "    idx_U = eig_U.argsort()[::-1]\n",
        "    idx_V = eig_V.argsort()[::-1]\n",
        "    U = U[:, idx_U]\n",
        "    V = V[:, idx_V]\n",
        "    S_vals = np.sqrt(np.abs(eig_V[idx_V]))\n",
        "    S = np.zeros((U.shape[1], V.shape[0]))\n",
        "    min_dim = min(len(S_vals), S.shape[0], S.shape[1])\n",
        "    S[:min_dim, :min_dim] = np.diag(S_vals[:min_dim])\n",
        "    return U, S, V.T\n",
        "\n",
        "# 5. Run SVD\n",
        "U, S, Vt = svd_scratch(X_centered)\n",
        "\n",
        "# 6. Results\n",
        "print(f\"X: {X_centered.shape}, U: {U.shape}, S: {S.shape}, Vt: {Vt.shape}\")\n",
        "recon = U @ S @ Vt\n",
        "print(f\"Error: {np.mean(np.abs(X_centered - recon)):.2e}\")\n",
        "\n",
        "# 7. Reduce to 2D\n",
        "k = 2\n",
        "X_2d = X_centered @ Vt[:k, :].T\n",
        "print(f\"2D shape: {X_2d.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Ia5s-xrcFnRK",
        "outputId": "cd845ccc-4def-4612-ffcd-bec6eb6e9b20"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: (36, 6), U: (36, 36), S: (36, 6), Vt: (6, 6)\n",
            "Error: 5.35e-01\n",
            "2D shape: (36, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SVD\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. Load + Select numeric\n",
        "train = pd.read_csv('/content/drive/MyDrive/ML_Datasets/wine_test.csv')\n",
        "X = train.iloc[:, 1:].values.astype(float)  # wine: 13 features\n",
        "\n",
        "# 2. Center\n",
        "X = X - X.mean(axis=0)\n",
        "\n",
        "# 3. SVD (Simple & Correct)\n",
        "def simple_svd(X):\n",
        "    m, n = X.shape\n",
        "    XtX = X.T @ X\n",
        "    eigvals, V = np.linalg.eig(XtX)\n",
        "    idx = np.argsort(eigvals)[::-1]\n",
        "    V = V[:, idx]\n",
        "    s = np.sqrt(np.maximum(eigvals[idx], 0))[:n]  # only n values\n",
        "    U = X @ V[:, :n] / s\n",
        "    return U, s, V[:, :n].T\n",
        "\n",
        "U, s, Vt = simple_svd(X)\n",
        "\n",
        "# 4. Reconstruct (CORRECT WAY)\n",
        "S_diag = np.diag(s)           # <-- YEH ZAROORI HAI!\n",
        "X_recon = U @ S_diag @ Vt     # <-- Ab shape match karega\n",
        "\n",
        "# 5. Error\n",
        "error = np.mean(np.abs(X - X_recon))\n",
        "\n",
        "# 6. Print\n",
        "print(f\"Samples: {X.shape[0]}, Features: {X.shape[1]}\")\n",
        "print(f\"Error: {error:.2e}\")\n",
        "print(f\"SC1: {s[0]**2/sum(s**2)*100:.1f}%\")\n",
        "print(f\"SC2: {s[1]**2/sum(s**2)*100:.1f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_YVysqv1L8zL",
        "outputId": "8462fdf7-20e8-44e2-ec3e-493d8cf04d05"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples: 36, Features: 13\n",
            "Error: 7.46e-14\n",
            "SC1: 99.8%\n",
            "SC2: 0.2%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "train = pd.read_csv('/content/drive/MyDrive/ML_Datasets/wine_train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/ML_Datasets/wine_test.csv')\n",
        "X_train = train.iloc[:,1:].values\n",
        "y_train = np.where(train['target']==0, -1, 1)\n",
        "X_test = test.iloc[:,1:].values\n",
        "y_test = np.where(test['target']==0, -1, 1)\n",
        "\n",
        "def stump_predict(X, f, t, d):\n",
        "    p = np.ones(len(X))\n",
        "    if d=='left': p[X[:,f]<t] = -1\n",
        "    else: p[X[:,f]>=t] = -1\n",
        "    return p\n",
        "\n",
        "def adaboost(X, y, T=10):\n",
        "    n = len(X); w = np.ones(n)/n; models = []\n",
        "    for _ in range(T):\n",
        "        best = (1,0,0,'left')\n",
        "        for f in range(X.shape[1]):\n",
        "            for t in np.unique(X[:,f]):\n",
        "                for d in ['left','right']:\n",
        "                    p = stump_predict(X,f,t,d)\n",
        "                    e = np.sum(w[p!=y])\n",
        "                    if e>0.5: e=1-e\n",
        "                    if e<best[0]: best = (e,f,t,d)\n",
        "        alpha = 0.5*np.log((1-best[0])/(best[0]+1e-10))\n",
        "        p = stump_predict(X, best[1], best[2], best[3])\n",
        "        w = w * np.exp(-alpha * y * p)\n",
        "        w /= w.sum()\n",
        "        models.append((alpha, best[1], best[2], best[3]))\n",
        "    return models\n",
        "\n",
        "# --- PREDICT (Direction use karo!) ---\n",
        "def predict(X, models):\n",
        "    s = np.zeros(len(X))\n",
        "    for a, f, t, d in models:           # ← d yahan bhi chahiye\n",
        "        s += a * stump(X, f, t, d)\n",
        "    return np.sign(s)\n",
        "\n",
        "# --- RUN ---\n",
        "models = adaboost(X_train, y_train, T=15)\n",
        "y_pred = predict(X_test, models)\n",
        "\n",
        "# Agar reverse ho → fix\n",
        "if np.mean(y_pred == y_test) < 0.5:\n",
        "    y_pred = -y_pred\n",
        "acc = np.mean(y_pred == y_test)\n",
        "print(f\" ACCURACY: {acc*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "h0cR9JaVNBtA",
        "outputId": "9f305939-ed13-49fb-b6e4-db6d8f2eccf7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ACCURACY: 88.89%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load datasets\n",
        "train = pd.read_csv('/content/drive/MyDrive/ML_Datasets/adult_train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/ML_Datasets/adult_test.csv')\n",
        "\n",
        "# Select only numeric columns (like you did)\n",
        "cols = [0, 2, 4, 10, 11, 12]\n",
        "X_train = train.iloc[:, cols].values\n",
        "X_test = test.iloc[:, cols].values\n",
        "\n",
        "# Normalize features (mean=0, std=1, use train stats!)\n",
        "def normalize(X, mean, std):\n",
        "    return (X - mean) / (std + 1e-8)\n",
        "\n",
        "mean = X_train.mean(axis=0)\n",
        "std = X_train.std(axis=0)\n",
        "X_train = normalize(X_train, mean, std)\n",
        "X_test = normalize(X_test, mean, std)\n",
        "\n",
        "# Convert target to -1 (for 0) and +1 (for 1)\n",
        "y_train = np.where(train['target'] == 0, -1, 1)\n",
        "y_test = np.where(test['target'] == 0, -1, 1)\n",
        "\n",
        "# Decision stump function\n",
        "def stump(X, feature, threshold, direction):\n",
        "    pred = np.ones(X.shape[0])\n",
        "    if direction == 'l':\n",
        "        pred[X[:, feature] < threshold] = -1\n",
        "    else:\n",
        "        pred[X[:, feature] >= threshold] = -1\n",
        "    return pred\n",
        "\n",
        "# AdaBoost fit function\n",
        "def adaboost(X, y, T=10):\n",
        "    n = len(X)\n",
        "    w = np.ones(n) / n\n",
        "    models = []\n",
        "\n",
        "    for _ in range(T):\n",
        "        best_err = 1\n",
        "        best_f, best_t, best_d = 0, 0, 'l'\n",
        "        for f in range(X.shape[1]):\n",
        "            thresholds = np.linspace(X[:, f].min(), X[:, f].max(), 20)\n",
        "            for t in thresholds:\n",
        "                for d in ['l', 'r']:\n",
        "                    preds = stump(X, f, t, d)\n",
        "                    err = np.sum(w[preds != y])\n",
        "                    if err > 0.5:\n",
        "                        err = 1 - err  # Use opposite\n",
        "                    if err < best_err:\n",
        "                        best_err = err\n",
        "                        best_f, best_t, best_d = f, t, d\n",
        "        # Check for degenerate error (avoid divide by zero)\n",
        "        if best_err == 0:\n",
        "            alpha = 10  # Large value\n",
        "        else:\n",
        "            alpha = 0.5 * np.log((1 - best_err) / (best_err + 1e-10))\n",
        "        preds = stump(X, best_f, best_t, best_d)\n",
        "        w = w * np.exp(-alpha * y * preds)\n",
        "        w = w / w.sum()\n",
        "        models.append((alpha, best_f, best_t, best_d))\n",
        "    return models\n",
        "\n",
        "# Prediction function\n",
        "def predict(X, models):\n",
        "    agg = np.zeros(X.shape[0])\n",
        "    for alpha, f, t, d in models:\n",
        "        agg += alpha * stump(X, f, t, d)\n",
        "    return np.sign(agg)\n",
        "\n",
        "# Train model\n",
        "models = adaboost(X_train, y_train, T=15)\n",
        "\n",
        "# Test\n",
        "y_pred = predict(X_test, models)\n",
        "acc = (y_pred == y_test).mean()\n",
        "print(f\" ACCURACY: {acc*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "L9gI79LEZMpu",
        "outputId": "72741d9e-3225-4309-efd4-5aef613e5fb0"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ACCURACY: 82.17%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oxJpWyTDaZ5r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}